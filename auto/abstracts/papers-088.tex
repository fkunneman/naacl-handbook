Most current chatbot engines are designed to reply to user utterances based on existing utterance-response (or U-R) pairs. In this paper, we present DocChat, a novel information retrieval approach for chatbot engines that can leverage unstructured documents, instead of U-R pairs, to respond to utterances. A learning to rank model with features designed at different levels of granularity is proposed to measure the relevance between utterances and responses directly. We evaluate our proposed approach in both English and Chinese: (i) For English, we evaluate DocChat on WikiQA and QASent, two answer sentence selection tasks, and compare it with state-of-the-art methods. Reasonable improvements and good adaptability are observed. (ii) For Chinese, we compare DocChat with XiaoIce, a famous Chinese chitchat engine, and side-by-side evaluation shows that DocChat is a perfect complement for chatbot engines using U-R pairs as main source of responses.
