If lexical similarity can hardly be used reliably to assess how word vectors will perform on specific tasks, what other ways do we have of evaluating representations? We propose a new task, which consists in extracting semantic differences using distributional models: given two words, what is the difference between their meanings? We present two proof of concept datasets for this task and outline how it may be performed.
