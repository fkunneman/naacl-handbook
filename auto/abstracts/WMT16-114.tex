This paper describes the University of Sheffield's submission for the WMT16 Multimodal Machine Translation shared task, where we participated in Task 1 to develop German-to-English and English-to-German statistical machine translation (SMT) systems in the domain of image descriptions. Our proposed systems are standard phrase-based SMT systems based on the Moses decoder, trained only on the provided data. We investigate how image features can be used to re-rank the n-best list produced by the SMT model, with the aim of improving performance by grounding the translations on images. Our submissions are able to outperform the strong, text-only baseline system for both directions.
