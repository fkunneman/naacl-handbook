Identifying the main claims occurring across texts is important for large-scale argumentation mining from social media. However, the claims that users make are often unclear and build on implicit knowledge, effectively introducing a gap between the claims.  In this work, we study the problem of matching user claims to predefined main claims, using implicit premises to fill the gap. We build a dataset with implicit premises and analyze how human annotators fill the gaps.  We then experiment with computational claim matching models that utilize these premises. We show that using manually-compiled premises improves similarity-based claim matching and that premises generalize to unseen user claims.
