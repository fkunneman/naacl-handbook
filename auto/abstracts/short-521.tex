Recently, neural network approaches for parsing have largely automated the combination of individual features,  but still rely on atomic features created from human linguistic intuition, and potentially omitting important global context. To further reduce feature engineering, we use bi-directional LSTM sentence representations and model a parser state with only three sentence positions, which allows the model to automatically identify important aspects of the entire sentence. This model achieves state-of-the-art results among greedy dependency parsers for English. We also introduce a novel transition system for constituency parsing which does not require binarization, and together with the above architecture, achieves state-of-the-art results among greedy parsers for both English and Chinese.
