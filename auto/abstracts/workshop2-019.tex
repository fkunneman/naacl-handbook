This paper presents a deep architecture for learning a similarity metric on variable- length character sequences. The model combines a stack of character-level bidi- rectional LSTM's with a Siamese archi- tecture. It learns to project variable- length strings into a fixed-dimensional em- bedding space by using only informa- tion about the similarity between pairs of strings. This model is applied to the task of job title normalization based on a manu- ally annotated taxonomy. A small data set is incrementally expanded and augmented with new sources of variance. The model learns a representation that is selective to differences in the input that reflect seman- tic differences (e.g., ``Java developer'' vs. ``HR manager'') but also invariant to non- semantic string differences (e.g., ``Java de- veloper'' vs. ``Java programmer'').
