The computing cost of many NLP tasks increases faster than linearly with the length of a sentence. In this paper we propose sentence chunking as a new task which simplifies further processing of long sentences. We use rules referring to the link structure of the sentence's Dependency Minimal Recursion Semantics (DMRS) representation to find appropriate chunking points in the graph representation and then to map those onto the sentence surface. Based on our preliminary experiments, we report an improvement in the precision of chunking from 19.6\% to 42\% compared with string heuristics. Currently we are working on using the rule-based system to generate a dataset of sufficient quality to be used as training material for a minimally supervised machine learning system. Then sentences could be chunked without creating a full parse first and we could apply chunking to an extended set of NLP tasks, such as statistical machine translation or parsing itself.
