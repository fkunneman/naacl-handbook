We present a simple yet effective approach for learning word sense embeddings. In contrast to existing techniques, which either directly learn sense representations from corpora or rely on sense inventories from lexical resources, our approach induces a sense inventory using existing word embeddings via clustering of ego-networks of related words. An integrated WSD mechanism enables labeling of word occurrences in context with the learned sense vectors, which gives rise to downstream applications. Experiments show that the performance of our method is comparable to  state-of-the-art unsupervised WSD systems.
