Adaptor  grammars  are                    a  flexible,  powerful formalism            for defining nonparametric,                     unsupervised  models  of  grammar        productions. This flexibility comes at the cost of expensive inference.  We address the difficulty of inference through an online algorithm which uses a  hybrid  of Markov                    chain  Monte  Carlo  and variational  inference.             We show  that this inference strategy improves scalability without sacrificing performance on unsupervised word segmentation and topic modeling tasks.
