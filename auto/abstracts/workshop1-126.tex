Bidirectional Recurrent Neural Networks (BiRNNs) have shown outstanding results on sequence-to-sequence learning tasks. This architecture becomes specially inter- esting for multimodal machine translation task, since BiRNNs can deal with images and text. On most translation systems the same word embedding is fed to both BiRNN units. In this paper, we present several experiments to enhance a base- line sequence-to-sequence system (Elliott et al., 2015), for example, by using dou- ble embeddings. These embeddings are trained on the forward and backward di- rection of the input sequence. Our sys- tem is trained, validated and tested on the Multi30K dataset (Elliott et al., 2016) in the context of the WMT 2016 Multimodal Translation Task. The obtained results show that the double-embedding approach performs significantly better than the tra- ditional single-embedding one.
