\begin{bio}
{\bfseries Jos\'{e} Camacho Collados} is a Google Doctoral Fellow and PhD student at the Sapienza University of Rome, working under the supervision of Prof. Roberto Navigli. His research focuses on Natural Language Processing and on the area of lexical semantics in particular. He has developed NASARI, a novel semantic vector representation for concepts and named entities, which led to two publications in NAACL and ACL 2015. Jos\'{e} will co-organize a SemEval 2017 task on multilingual semantic similarity. His background education includes an Erasmus Mundus Master in Natural Language Processing and Human Language Technology and a 5-year BSc degree in Mathematics.

{\bfseries Ignacio Iacobacci} is a PhD student at the Sapienza University of Rome, working under the supervision of Prof. Roberto Navigli. His research interests lie in the fields of Machine Learning, Natural Language Processing, Neural Networks. He is currently working on Word Sense Disambiguation and Distributional Semantics. Ignacio presented SensEmbed at ACL 2015, a novel approach for word and relational similarity built from exploiting semantic knowledge for modeling arbitrary word senses in a large sense inventory. His background includes a MSc. in Computer Science and 8 years as a developer including 4 years as a Machine Learning - NLP specialist.

{\bfseries Roberto Navigli} is an Associate Professor in the Department of Computer Science at La Sapienza University of Rome and a member of the Linguistic Computing Laboratory. His research interests lie in the field of Natural Language Processing, including: Word Sense Disambiguation and Induction, Ontology Learning, Knowledge Representation and Acquisition, and multilinguality. In 2007 he received a Ph.D. in Computer Science from La Sapienza and he was awarded the Marco Cadoli 2007 AI*IA national prize for the Best Ph.D. Thesis in Artificial Intelligence. In 2013 he received the Marco Somalvico AI*IA prize, awarded every two years to the best young Italian researcher in Artificial Intelligence. He is the creator and founder of BabelNet, both a multilingual encyclopedic dictionary and a semantic network, and its related project Babelfy, a state-of-the-art multilingual disambiguation and entity linking system. He is also the Principal Investigator of MultiJEDI, a 1.3M euro 5-year Starting Grant funded by the European Research Council and the responsible person of the Sapienza unit in LIDER, an EU project on content analytics and language technologies. He is also the Co-PI of ``Language Understanding cum Knowledge Yield'' (LUcKY), a Google Focused Research Award on Natural Language Understanding.

{\bfseries Mohammad Taher Pilehvar} is a Research Associate in the Language Technology Lab of the University of Cambridge where he is currently working on NLP in the biomedical domain. Taher completed his PhD in 2015 under the supervision of Prof. Roberto Navigli. Taher's research lies in lexical semantics, mainly focusing on semantic representation, semantic similarity, and Word Sense Disambiguation. He has co-organized two semeval tasks and has authored multiple conference and journal papers on semantic representation and similarity in top tier venues. He is the first author of a paper on semantic similarity that was nominated for the best paper award at ACL 2013.
\end{bio}

\begin{tutorial}
  {Semantic Representations of Word Senses and Concepts}
  {tutorial-004}
%  {Jos\'{e} Camacho-Collados, Ignacio Iacobacci, Roberto Navigli and Mohammad Taher Pilehvar}
  {\daydateyear, \tutorialmorningtime}
  {\TutLocD}

Representing the semantics of linguistic items in a machine-interpretable form has been a major goal of Natural Language Processing since its earliest days. Among the range of different linguistic items, words have attracted the most research attention. However, word representations have an important limitation: they conflate different meanings of a word into a single vector. Representations of word senses have the potential to overcome this inherent limitation. Indeed, the representation of individual word senses and concepts has recently gained in popularity with several experimental results showing that a considerable performance improvement can be achieved across different NLP applications upon moving from word level to the deeper sense and concept levels. Another interesting point regarding the representation of concepts and word senses is that these models can be seamlessly applied to other linguistic items, such as words, phrases, sentences, etc.

This tutorial will first provide a brief overview of the recent literature concerning word representation (both count based and neural network based). It will then describe the advantages of moving from the word level to the deeper level of word senses and concepts, providing an extensive review of state-of-the-art systems. Approaches covered will not only include those which draw upon knowledge resources such as WordNet, Wikipedia, BabelNet or FreeBase as reference, but also the so-called multi-prototype approaches which learn sense distinctions by using different clustering techniques. Our tutorial will discuss the advantages and potential limitations of all approaches, showing their most successful applications to date. We will conclude by presenting current open problems and lines of future work.
\end{tutorial}
