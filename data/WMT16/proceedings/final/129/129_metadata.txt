SubmissionNumber#=%=#129
FinalPaperTitle#=%=#DCU-UvA Multimodal MT System Report
ShortPaperTitle#=%=#DCU-UvA Multimodal MT System Report
NumberOfPages#=%=#5
CopyrightSigned#=%=#Iacer Calixto
JobTitle#==#
Organization#==#ADAPT Centre. School of Computing, Dublin City University (DCU), Glasnevin, Dublin 9, Dublin, Ireland.
Abstract#==#We present a doubly-attentive multimodal machine translation model. Our model
learns to attend to source language and spatial-preserving CONV 5,4 visual
features as separate attention mechanisms in a neural translation model. In
image description translation experiments (Task 1), we find an improvement of
2.3 Meteor
points compared to initialising the hidden state of the decoder with only the
FC 7 features and 2.9 Meteor points compared to a text-only neural machine
translation baseline, confirming the useful nature of attending to the CONV 5,4
features.
Author{1}{Firstname}#=%=#Iacer
Author{1}{Lastname}#=%=#Calixto
Author{1}{Email}#=%=#calixto.iacer@gmail.com
Author{1}{Affiliation}#=%=#Dublin City University
Author{2}{Firstname}#=%=#Desmond
Author{2}{Lastname}#=%=#Elliott
Author{2}{Email}#=%=#d.elliott@uva.nl
Author{2}{Affiliation}#=%=#University of Amsterdam
Author{3}{Firstname}#=%=#Stella
Author{3}{Lastname}#=%=#Frank
Author{3}{Email}#=%=#s.c.frank@uva.nl
Author{3}{Affiliation}#=%=#University of Amsterdam

==========