%
% File acl2016.tex
%
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2016}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{verbatim}
\usepackage{tikz}
\usepackage[ruled]{algorithm2e} 
\usepackage{graphics}
\usepackage{mdframed}
\usepackage{tikz-dependency}
\usepackage{pst-node}
\usepackage{gb4e}
\usetikzlibrary{shapes,arrows,shadows}
\usepackage{amsmath,bm,times}
\usepackage{amsmath}
\usepackage{placeins}
\usepackage{color,soul}
\usepackage{tree-dvips}
\usepackage{graphicx}
\usepackage{booktabs}


\aclfinalcopy  
\def\aclpaperid{51} %  Enter the acl Paper ID here

\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}
\newcommand*{\Scale}[2][4]{\scalebox{#1}{$#2$}}%


\title{Implicit Semantic Roles in a Multilingual Setting }

\author{Jennifer Sikos \qquad Yannick Versley \qquad Anette Frank\\
  Department of Computational Linguistics \\
  Heidelberg University, Germany\\
  Leibniz Science Campus ``Empirical Linguistics and Computational Language Modeling"\\
  {\tt \{sikos, versley, frank\}@cl.uni-heidelberg.de} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
Extending semantic role labeling (SRL) to detect and recover non-local arguments continues to be a challenge. Our work is the first to address the detection of implicit roles from a multilingual perspective. We map predicate-argument structures across English and German sentences, and we develop a classifier that distinguishes implicit arguments from other translation shifts. Using a combination of alignment statistics and linguistic features, we achieve a precision of 0.68 despite a limited training set, which is a significant gain over the majority baseline. Our approach does not rely on pre-existing knowledge bases and is extendible to any language pair with parallel data and dependency parses.
%Our approach is knowledge-lean, relying only on dependency-parsed input. -- I changed this since we're also relying on word alignments and parallel corpora; Also, it is misleading to talk about the input, since the classifier with .68 precision actually takes manually annotated examples as input. I think it's problematic to make this input statement.
\end{abstract}

\section{Introduction}
Understanding events and their participants is a core NLP task, and SRL is the standard approach for identification and labeling of these events in text. SRL systems \cite{tackstrom2015efficient,roth2014composition} have benefited NLP applications, and many approaches have been proposed to transfer semantic roles from English to other languages without further reliance on manual annotation \cite{kozhevnikov2013cross,pado2009cross}. However, event structures -- both predicates and their arguments -- are known to shift in the translation process, and this poor correspondence presents a bottleneck for the transference of semantic roles across languages. In some cases, the semantic content of an entire argument can be missing from the scope of its translated predicate. 

Arguments that are omitted are often treated as noise in state-of-the-art projection models; however, our work views them as a valuable source of data - such arguments serve as naturally occurring training data for \textit{implicit}
role detection.  We target arguments that have been dislocated from their predicates, or are dropped entirely, in translated sentences. These non-isomorphic event structures can not only be leveraged as new training data for implicit role detection, but analyzing the shifts that trigger these implicit roles can guide improvements to systems that perform cross-lingual semantic role projection. %multilingual SRL.

{\bf  \flushleft Implicit Roles}
If a predicate is known to have multiple semantic arguments, only a subset might be expressed within the local boundary of its clause or sentence. SRL models typically restrict their search for semantic arguments to this local domain and are not designed to recover
arguments situated in the broader discourse context. 
Non-local role linking extends the SRL task by recovering the semantic arguments not
instantiated in the local scope of the predicate. One complicating factor is that these implicit arguments can either be found in the context, and thereby are recoverable, or they could be existentially interpreted and might not correspond to any referent in the text at all. In the examples below, the argument for the predicate \underline{withdrawn} in (1) is resolvable
while the implicit argument for \underline{reading} in (2) is not:

\exewidth{0}
\begin{exe}
\ex El Salvador is now the only Latin American country which still has troops in [Iraq]\footnote{In this and other examples throughout the paper, the brackets [] indicate the antecedent of the implicit argument.}. Nicaragua, Honduras, and the Dominican Republic have \underline{withdrawn} their troops {\o}.\\
\textit{Implicit role: Location}
\ex I was sitting \underline{reading} {\o} in the chair.\\
\textit{Implicit role: Theme}
\end{exe}

Implicit role labeling systems consistently report low performance 
 due to lack of training data. Combining the few existing re\-sour\-ces improves performance \cite{feizabadi2015combining} when they contribute diversity in predicate and argument types. Since much of the multilingual parallel corpora vary in domain and genre, mining these corpora for implicit roles should provide new training data that is sufficiently diverse to benefit the implicit role labeling task.

{\bf \flushleft Predicate-Argument Structures across Languages}
Translational correspondences have been used in previous work to acquire resources for supervised monolingual tasks, such as word sense disambiguation \cite{diab2002unsupervised}.
Similarly, semantic role annotations can be transferred to new languages 
when predicate-argument structures are stable across language pairs \cite{pado2009cross}. 
In this work, we target predicate-argument structures that 
do not express such stability and have shifted in the translation process. In example (3), the role \textit{farmers} is dropped entirely in the aligned German sentence:%\footnote{{\color{red} Is this a resolvable role and can you show the antecedent?}}

\begin{exe}
\ex The only change is that [farmers] are not \underline{required} to produce.
 \vspace*{-2mm}
\gll Die einzige Neuerung ist, dass nicht \underline{gefordert} wird zu produzieren.\\
The only change is, that not required are to produce.\\
\end{exe}


The challenge in detecting implicit roles across languages is that these omissions represent only a fraction of the kinds of poor alignments that can occur. In fact, different types of translational shifts may occur that do not constitute cases of implicit role omission.
%are capable of lowering the performance of semantic role projection. 
Such factors include: change in part-of-speech from a verbal predicate to a noun or adjective, light verb constructions, single predicates that are expressed as both a verb and complement in the target language, and expressions with no direct translations \cite{samardvzicscope}.


{\bf \flushleft Aims and Contributions}
To find implicit (non-local) semantic roles in translation, we distinguish role omissions from other types of translation shifts. We test linguistic features to automatically detect such role omissions in parallel corpora. 
We divide our work into alignment (Section 3.1) and classification (Section 3.2), with an annotation task for data construction (Section 4). 

Our contributions are (i) a novel method for automatically identifying implicit roles in discourse, (ii) a classifier that is able to distinguish general translational divergences from true cases of implicit roles, (iii) an annotated, multilingual dataset of manually tagged implicit arguments, and (iv) a classifier that achieves precision of 0.68 despite a small training set size, which is a significant improvement over a majority class baseline. Finally, we perform detailed analysis of our annotation and automatic classification results. 

\section{Related Work}
\subsection{Implicit Semantic Role Labeling}
Previous resources for implicit SRL were developed over diverging schemas, texts, and predicate types. An initial dataset was constructed in the SemEval-2010 Shared Task ``Linking Events and Their Participants in Discourse'', under the FrameNet paradigm; authors annotated short stories with implicit arguments and their antecedents, resulting in approx. 500 resolvable and 700 non-resolvable implicit roles out of roughly 3,000 frame instances \cite{ruppenhofer2010semeval}. Gerber and Chai \shortcite{gerber2010beyond} focused on the implicit arguments of a constrained set of 10 nominal predicates in the NomBank scheme, annotating 966 implicit role instances for these specific predicates.

Numerous 
studies on the recovery of implicit roles have concluded that a lack of training data has been the stopping point towards improvements on the implicit role labeling task \cite{gorinski2013towards,laparra2013impar}. To address this problem,
\newcite{silberer} generated artificial training data by removing arguments from coreference chains and showed that adding such instances yields performance gains. 
However, their quality was low and later work \cite{rothfrank2015} has shown that smaller numbers of naturally occurring training data performed better.
\newcite{rothfrank2015} applied a graph-based method for automatically acquiring high-quality data for non-local SRL using comparable monolingual corpora. They detect implicit semantic roles across documents and their antecedents from the prior context, again following cross-document links. In contrast, our work does not rely on semantic resources (SRL and lexical ontologies), but builds on parallel corpora enriched with dependencies and word alignments.
Finally, \newcite{stern-dagan2014P14-2} generate training data for implicit SRL from textual entailment data sets. However, this type of resource needs to be manually curated.

\subsection{Cross-lingual Annotation Projection}
% The growing availability of parallel, multilingual corpora provides more opportunities for exploiting translations to benefit NLP tasks.

Aside from English, resources for SRL only exist for a select number of languages. For the languages that have such resources, annotated data still tends to vastly underrepresent the variability and breadth of coverage that exists for English. To extend SRL to new languages without reliance on manual annotation, models for role transference have been developed under both the supervised
\cite{pado2009cross,akbikgenerating} and unsupervised \cite{kozhevnikov2013cross}  setting. Most relevant to our work are previous studies that address the problem of projecting semantic role annotations across parallel corpora.

To transfer semantic annotations across languages, \newcite{pado2009cross} score the constituents of word-aligned parallel sentences and project role labels for the arguments that achieve highest constituent alignment scores. Akbik et al \shortcite{akbikgenerating} use filtered projection by constraining alignments through lexical and syntactic filters to ensure accuracy in predicate and argument role projection. Complete predicate-argument mappings are then used to bootstrap a classifier to recover further unaligned predicates and arguments.
%
%\paragraph{Implicit Role Detection}\footnote{{\color{red} new, please complete.}} [SemEval task] has introduced the sub-task of INI/DNI role detection in non-local role assignment. Classifiers were defined on the basis of locally assigned predicate and semantic role assignments. Features include ... Classifiers obtain relatively high performance [give nbs]. These classifier models are specific to the FN scheme, they rely on (local) SRL systems and resources, and they are restricted to core semantic roles. Our method is resource-lean, being dependent only on dependency-parsed input for the source and target language pairs. --this section doesn't seem necessary since the focus of the paper is on the generation of new data and not non-local role linking.

\section{Detecting Implicit Roles across Languages}
We hypothesize that implicit semantic roles can be found in translated sentences, even in corpora where sentences are typically close translations. Our goal is to distinguish implicit roles from other translation shifts that cause poor alignment in SRL projection. A model is constructed based on lexical, syntactic,  and alignment properties of parallel predicate-argument structures, and this classifier is, to the best of our knowledge, the first to detect a wide range of omitted roles in multilingual, parallel corpora. Our implicit role detection applies to both core and non-core arguments and is not dependent on large-scale SRL resources.

\subsection{Identifying Poorly Aligned Arguments}

\begin{figure*}[!ht]
\begin{minipage}[thb!]{.55\textwidth}
\includegraphics[width=8cm]{graphic2.png}

\end{minipage}
\qquad
\begin{minipage}[thb!]{\hsize}
\begin{tabular}{@{}l|lc@{}}
\small Alignment & \small Aligned& \small Alignment\\
\small Type & \small Arguments& \small Score\\
\hline
\small \textit{headword}     & \small \textit{a_1^{sl},--} & \small 0 \\
     & \small \textit{a_2^{sl},a_1^{tl}} & \small 1 \\
   & \small \textit{a_3^{sl},--} & \small 0 \\
\hline
\small {\em ascore} &  \small \textit{a_1^{sl},--^{tl}} & \small 0 \\
 & \small \textit{a_2^{sl},a_1^{tl}}  &  \small (1 + 1)/2 = 1.0\\
  & \small \textit{a_3^{sl},a_3^{tl}}  &  \small (2/3 + 2/3)/2 = 0.67\\

\end{tabular}
\end{minipage}

\caption{Predicate-argument structures with noisy word alignments (left), and alignment scores for the arguments (right). \textit{Headword} scoring aligns only headwords of the source (\textit{a^{sl}}) and target (\textit{a^{tl}}) arguments, while {\em ascore} uses headwords and dependents of an entire argument span for alignment.}\label{fig1}

\end{figure*}

Our first goal is  to find candidates for implicit arguments by aligning predicate-argument structures across parallel English and German sentences. 

{\bf  \flushleft Predicate and Argument Identification}
We target all non-auxiliary verbs as predicates, and  detect their dependents through grammatical relations in dependency parses. We extract subjects, direct objects, indirect objects, prepositional objects, adverbial or nominal modifiers as well as embedded clauses. These recover both the core and non-core arguments (adjuncts) of the predicate.\footnote{Since  we are treating arguments and adjuncts alike, in the following we loosely refer to both types of dependents as `arguments'.} Arguments are attached to their nearest predicate and cannot be attached to more than one, as might occur in cases of embedded clauses.%\footnote{{\color{red} I omitted the last sentence, since it is only done to compute the yield of argument candidates.}} 
%We additionally retrieve argument dependents, again with the caveat that dependents can only be attached to their most direct argument.

{\bf  \flushleft Aligning Arguments for Detection of Unaligned Roles}
We use word alignments between parallel source (\textit{sl}) and target (\textit{tl}) language sentences as input. A predicate in the source language $p^{sl}$ is mapped to a predicate in the target language $ p^{tl}$  if there exists a word alignment link between them, and their arguments are then aligned using the scoring function $ArgAL_p$ (Eq 3). $ArgAL_p$ uses word alignment links between the source and target arguments $a^{sl}$, $a^{tl}$ of the aligned predicate pair to produce an optimal mapping between corresponding predicate-argument structures. 

For scoring, we adapt  \newcite{pado2009cross}'s constituent alignment-based overlap measure (Eq \ref{eq:jacc}) to dependencies, where $yield(a)$ denotes the set of words in the yield (headword and dependents) of an argument $a$, and $align(a)$ the set of words in the target language that are aligned to the yield of $a$. Because the automatic word alignment tool gives predictions for links in both directions, we apply this asymmetric measure from the English-German and German-English links and average their results (Eq \ref{eq:ascore}). %\footnote{{\color{red} Formula changed; better explanation of what E3 does; it would be better to have sl/tl as subscripts, rather than superscripts; eliminated sl in $p^{sl}$ in ArgAL(p).}}
The {\em ascore} is computed for the Cartesian product $A^{sl}$ $\times$ $A^{tl}$ over all source and target arguments of the aligned predicates $p^{sl}$ and $p^{tl}$.
We select the argument alignments ${A'}^{sl}$ $\times$ ${A'}^{tl}$ $\subseteq$ $A^{sl}$ $\times$ $A^{tl}$  that return the maximal sum of scores for all arguments across the aligned argument structure (Eq \ref{eq:maxsumofscores}).

Anticipating noise in the word alignments, we set a threshold to enforce accurate mappings between arguments. From the obtained mappings, we consider any argument whose alignment score does not exceed a threshold $\Theta$ as {\em unaligned} and thus as a candidate for an implicit role. The selection of threshold $\Theta$ is discussed in Section 5.
\begin{equation}
{ovlp(a^{sl},a^{tl}) = \frac{\mid align(a^{sl}) \cap yield(a^{tl})\mid}{\mid align(a^{sl}) \cup yield(a^{tl})\mid}}
\label{eq:jacc}
\end{equation}
 \vspace*{-2mm}
\begin{equation}
{ascore(a^{sl},a^{tl})=\frac{ovlp(a^{sl},a^{tl})+ ovlp(a^{tl},a^{sl})}{2}}
\label{eq:ascore}
\end{equation}
 \vspace*{-5mm}
\begin{align}\label{eq:maxsumofscores}
\begin{split}
\Scale[0.85]
{{ArgAL_p} = \underset{{A'}^{sl}\times {A'}^{tl} \subseteq  A^{sl} \times A^{tl}} {\operatorname*{arg\,max}} \sum_{A^{sl} \times A^{tl}} ascore(a^{sl},a^{tl}) }\\
\mbox{\small where}\\
\Scale[0.85]{A^{sl}\times A^{tl} =\{\langle a^{sl},a^{tl}\rangle \mid a^{sl} \in \langle p^{sl},a^{sl} \rangle, a^{tl} \in \langle p^{tl},a^{tl}\rangle\}}
%{{ArgAL(p)} = \underset{\langle {A'}^{sl},{A'}^{tl}\rangle \subseteq \langle A^{sl},A^{tl}\rangle} {\operatorname*{arg\,max}} \sum_{\langle A^{sl}A^{tl}\rangle} ascore(a^{sl},a^{tl}) }\\
%\mbox{\small where}\\
%\Scale[0.85]{\langle A^{sl},A^{tl}\rangle=\{\langle a^{sl},a^{tl}\rangle \mid a^{sl} \in \langle p^{sl},a^{sl} \rangle, a^{tl} \in \langle p^{tl},a^{tl}\rangle\}}
\end{split}
\end{align}
 \vspace*{-5mm}

 An example of the alignment scoring is given in Figure \ref{fig1}, where predicates and arguments are detected over parallel English-German sentences, and word alignments are automatically generated. The argument `an in-depth analysis' consists of a headword and two dependents, with two noisy word alignments that link the arguments across languages. Given these word alignment links, the {\em ascore} (Eq \ref{eq:ascore}) is computed by taking the number of alignments and the yield of the arguments for both English and German, and these scores are then averaged for a final alignment score of 0.67. In this case, the scoring function still produces correct mappings across the predicate-argument structures despite imperfect word alignments, and an implicit role, \textit{We}, is correctly unaligned to the German sentence.
 %\footnote{{\color{red} @JS: give a better description/explanation of Figure 1 in the text, as well as explanations for notation/table in the caption.}} --given above

\subsection{Classification of Poor Alignments as Implicit Roles}
Our objective is to build a classifier that automatically detects implicit roles across parallel corpora. To achieve this goal, we construct a classifier that takes as input an unaligned argument in English and, based on linguistic features in the aligned English and German sentences, determines whether this unaligned argument is an implicit role in German. Our dataset, described in Section 4.2, consists of instances of poorly aligned roles that have been annotated as either \textit{implicit, not implicit,} or \textit{not a role of the predicate}. In classification, we reduce the annotation classes (\textit{implicit/not implicit/not a role of the predicate}) to a binary decision where the positive class represents the implicit roles, and the negative class is any unaligned argument that annotators determined as either \textit{not implicit} or \textit{not a semantic role}. We reduced the task to a binary decision to avoid sparsity in the classification.

{\bf  \flushleft Features}
We hypothesize that we can predict the existence of an implicit role through features of the predicate-argument structures in the source and target languages. These features include monolingual predicate-argument structures, as well as cross-lingual features that represent the quality of the alignments across the parallel sentences. Monolingual features encode the syntactic properties of the arguments and predicates for source and target sentences, as well as sentential-level features that include the presence of modal and auxiliary verbs and conjunctions. To incorporate cross-lingual information, the alignment scores described in Section 3.1 are kept as features to the classifier, based on our assumption that the overall alignment between source and target predicate-argument structures should impact the classification of an implicit role. Both monolingual and cross-lingual features apply to surrounding predicate/arguments, where arguments can either be aligned or unaligned, and predicates that have fully aligned structures are considered \textit{complete}. A complete list of features is shown in Table \ref{features}.
\begin {table}[h]
\begin{tabular}{@{}p{1.5cm}p{4.3cm}llrc@{}}
\hline
\tiny TYPE  & \tiny FEATURE & \tiny XLING \\
\hline
\small Argument &  \small Lemma\\
\small    & \small POS\\
\small   & \small Grammatical relation to predicate\\
\small      & \small Distance to predicate\\
\small      & \small Number of dependents\\
\small      & \small Syntactic path to predicate\\
\small       & \small Alignment type of neighboring argument ({\em aligned, unaligned}) & \tiny +\\
\hline
\small Predicate &  \small Lemma\\
\small     & \small POS\\
\small     & \small Total number of arguments\\
\small      & \small Number of aligned arguments & \tiny +\\
\small      & \small Number of unaligned arguments & \tiny +\\
\small      & \small \textit{ArgAL$_p$} score & \tiny +\\
\small    & \small Alignment type of neighboring predicate ({\em complete, incomplete}) & \tiny +\\
\hline
\small Sentential     & \small   Presence of a modal or auxiliary  \\
\small    & \small   Sentence-final punctuation marks before end \\
\small      & \small   Conjunction between  \small \textit{p^{sl},p^{sl}-1} \\
\small      & \small   Sum of  \small \textit{ArgAL$_p$} scores  \\
\small      & \small   Total number of arguments  \\
\small      & \small   Total number of predicates  \\
\small      & \small   Sum of  \small \textit{ArgAL$_p$ scores} over all predicates & \tiny +\\
\hline
\end{tabular}
\caption{Features investigated for classification, where Xling are cross-lingual features.}\label{features}
\end{table}

{\bf  \flushleft Classifiers}
We experimented with three classifiers, a Support Vector Machine (SVM) with a linear kernel, Decision Tree, and Gradient Boosting, under the framework of the Scikit-learn library \cite{scikit-learn}. 
 
\section{Constructing a Dataset for Classifying Implicit Arguments}

This section presents the construction of our experimental dataset for  implicit role detection.

\subsection{Corpora and Tools}
We conduct our experiments over the Europarl corpus \cite{koehn2005europarl}, which contains over 1.9 million aligned sentences in our target languages. %.\footnote{{\color{red}Give also the number of aligned sentences. It is smaller!}} -- aligned sentences is 1.9 million
Anticipating noise in the automatic word alignments, we first take sentences from manually word-aligned German-English Europarl data \cite{pado05cross} to conduct our initial experiments. These sentences give us an upper bound for the number of implicit roles we should expect to obtain. Automatic word alignments are generated with GIZA++ \cite{och03:asc}.%moved this sentence up from below
%{\color{red} ADD: how many aligned sentences from Europarl were used to extract poorly aligned arguments = the 200 candidate cases for implicit role classification stemming from automatically aligned Europarl sentence pairs} --this information is given below, in the Annotation Results section. 

Predicates and their arguments are first detected through dependency parses on English and German parallel corpora. Parses are generated for English with ClearNLP \cite{choi2013transition}. German sentences are run through the MarMot morphological analyzer \cite{muller2013efficient}, and dependency parses for German are then generated using the RBG Parser \cite{lei2014low}. The Universal Dependencies project facilitates cross-lingual consistency in parsing and provides better compatibility amongst multiple languages. We trained the RBG Parser with the Universal Dependencies tagset \cite{rosa2014hamledt}, and thus our argument detection can be applied to other languages in the Universal Dependencies project.

\subsection{Annotation of Poorly Aligned Arguments}

{\bf \flushleft Annotation Instances}
Our goal is to find any argument that is either missing or dislocated from its predicate in translation. With this objective in mind, we focused our annotation on incomplete predicate structures whose argument(s) remained unaligned. Any argument with scores below the alignment threshold (see Section 3.1) was a candidate for annotation.

{\bf  \flushleft Annotation Task and Guidelines}
Three annotators worked on this task. Each annotator was a native German speaker with high fluency in English, and had taken at least one undergraduate course in linguistics. Annotators were given guidelines that define predicates as \textit{events} or \textit{scenarios}, and semantic roles as an element that has a semantic dependence on the predicate, including the \textit{who, what, where, when,} and \textit{why} type of information. Implicit roles were defined as ``any role that is missing from the scope, or clausal boundary, of the predicate''.  Each annotator was trained on a test set of 10 example sentences.%\footnote{{\color{red}@JS: rearrange the Questions and Answers in Figure 2, such that Answer instructions are directly following the Question; also insert a dividing line between presented examples and question-answer area}} -- addressed in the figure

\begin{figure}[t!]
	\begin{mdframed}
		\small{Context - 2 preceding English sentences \
			\begin{center}
				------
			\end{center}
			The only change is that [farmers] are not --required-- to produce . \\
			Die einzige Neuerung ist , dass nicht --gefordert-- wird zu produzieren . \
			\begin{center}
				------
			\end{center}
			Context - 2 preceding German sentences
			
			\begin{center}
			----------------------------------------------------------------
			\end{center}
			
			[farmers]\\
			Can `farmers' be considered a role of the English predicate `required'?\\ \\
			If `no': please choose:\\
			not a role of English predicate\\\\
			Can `farmers' be considered an implicit role for the German predicate `gefordert'?\\\\
			If `no': please choose:\\
			not an implicit role of German predicate  \\
			If `yes': please indicate the location of the German translation of `farmers' by marking it in (**)}\\
		
	\end{mdframed}
	\caption{Example annotation task. Aligned predicates are marked in dashes (--) and implicit role candidates are surrounded by squared brackets [].}\label{annotask}
	
\end{figure}


Annotators were given pairs of sentences with aligned predicates in English and German, where the English predicate had a poorly aligned argument. Annotation instances were presented as: two preceding English sentences, the English sentence with both the argument and predicate highlighted, the German sentence with the aligned predicate highlighted, and two preceding German sentences. An example of the annotation task is shown in Figure \ref{annotask}.

The annotation task was broken into two subtasks. First, annotators were asked to judge whether the marked argument is a correct semantic role for the English predicate. The second subtask asked annotators to judge whether a translation for the argument was available in the scope of the highlighted German predicate. If it was not available in the scope, they were asked to annotate the example as \textit{implicit}. 

{\bf  \flushleft Difficult Annotation Cases}
The annotations were adjudicated by one of the authors, and the annotator with the highest agreement with the adjudicator was asked to complete the entire dataset. 

Cases that resulted in higher annotator disagreement included arguments of nominal predicates that were themselves the argument of the aligned predicate. In Example 4 below, \textit{30 August} is a role for the nominal predicate \textit{participation} but not \underline{continue}:
\exewidth{(0)}
\begin{exe}
\ex The massive participation [from 30 August] must \underline{continue}.
\end{exe}

Other difficult annotation cases included roles that were partially, or entirely, encoded in the translated predicate. These included temporal adjuncts that could either be interpreted as present tense or implicit in the translated sentence:
\exewidth{(0)}
\begin{exe}
\ex I will [now] \underline{give} the floor to the President \vspace*{-2mm}
\gll Ich  \underline{gebe} dem Pr{\"a}sidenten das Wort \\
I  give the President the floor \\
\end{exe}

After a review of these difficult cases, annotation guidelines were modified and annotators were re-trained. 

{\bf \flushleft Annotation Quality}
Inter-annotator agreement was measured by Cohen's Kappa scores over 114 instances, and the entire 700 candidates were then completed by Annotator 1. One of the authors adjudicated for agreement. 
Results are given in Table \ref{agreement} where ``Role + Implicit'' reports Kappa scores over all three categories - \textit{not a role, implicit, and not implicit,} while ``Implicit'' reports agreement over binary \textit{implicit} vs \textit{non-implicit} decisions.
%{\footnote{\color{red} Removed the third example of difficult annotation examples - annotator had difficulties with clausal boundaries }}


\begin{table}[h]
\centering
\begin{tabular}{@{}lllr@{}}
\hline
\cline{1-3}
\tiny ANNOTATOR  vs ADJUDICATOR & \tiny ROLE \tiny + \tiny IMPLICIT  &\tiny IMPLICIT\\
\hline
\small \tiny ANNOTATOR 1  & \small 0.76 & \small 0.96     \\
\small \tiny ANNOTATOR 2   & \small 0.48 &\small 0.92     \\
\small \tiny ANNOTATOR 3 & \small 0.29 & \small 0.69      \\
\hline
\end{tabular}
\caption{Kappa agreements}\label{agreement}
\end{table}

%{\footnote{\color{red} This table was still referenced in the text but missing in the latest version - is there a reason it was removed? }}

{\bf \flushleft Annotation Results }
In total, we took 700 poorly aligned arguments whose scores were below the alignment threshold (Section 3.1), where 500 were selected from manual word alignments and 200 from GIZA++ alignments. The 500 candidate arguments were sampled from 987 gold-aligned Europarl sentences, in which over 3,000
%3,816 arguments
 arguments fell below the threshold. The 200 candidates were sampled from 500
%3000 - looking back, the 3000 (exactly 2,996) was for the number of unaligned arguments - not sentences! The number of sentences was 500
%{\color{red} XXX}\footnote{{\color{red}JS: insert number, also numbers in table (need to split between manual and GIZA)}} --numbers inserted to the table
automatically aligned Europarl sentence pairs (excluding the sentences from the manually aligned dataset), with nearly 3,000 arguments below the threshold, to estimate the difference in implicit roles between manual and automatic word alignments.

Over the completed dataset, results for the annotation types are given in Table \ref{tbl:annotationresults}. Out of the manually aligned Europarl sentences, annotations produced 45 positive implicit role instances (9{\%} of the annotated candidates). The automatic alignments, with 200 examples, contained 6 instances (3{\%} of the annotated candidates) of implicit roles. Over the total 700 instances, 24.5{\%} were classified as `not a predicate role', 68.3\% as `not implicit', and 7.2\% as `implicit'.%\footnote{{\color{red} Tables have changed -- insert named references to tables and Figures}} 

\begin{table}[h]
	\small
\begin{tabular}{@{}lllllr@{}}
	\toprule
&  \tiny INSTANCES & \tiny NOT A ROLE & \tiny NOT IMPLICIT & \tiny IMPLICIT\\
	 Manual  & 500 & 154 & 301 & 45  \\
	 GIZA++ & 200 & 18 & 176 & 6\\   
	\bottomrule
\end{tabular} 

\if false
\hspace*{3mm}
\begin{tabular}{p{1.5cm}p{0.5cm}ll}
	\hline
	\cline{1-2}
	\scriptsize Annotation Type & \scriptsize Count \\
	\hline
	\scriptsize Not a predicate role & \scriptsize 172 \\
	\hline
	\scriptsize Not implicit & \scriptsize 477 \\
	\hline
	\scriptsize Implicit & \scriptsize51 \\
	\hline
\end{tabular}
\fi
\caption{Final annotation dataset.}\label{tbl:annotationresults}
\end{table}

\if false
\begin{table}[h]
\centering
\begin{tabular}{lllr}
\hline
\cline{1-4}
\small
Alignment & \small Complete PAS & \small Aligned A & \small Unaligned A\\
\hline
\tiny MANUAL  & \small 859 & \small 3528  & \small  3816 \\
\tiny GIZA++  & \small 143 &\small 650  & \small  6242 \\
\hline
\end{tabular}
\caption{Aligned predicate-argument structures.}\label{tab:accents}
\end{table}
\fi

\section{Classification Experiments and Results}

\subsection {Argument Alignment and Scoring}
With the scoring function described in Section 3.1, perfectly aligned arguments should produce a score of 1.0. We experimentally set the threshold $\Theta$ for the minimum alignment score at 0.2 for arguments such that arguments with imperfect word alignments will still be aligned. 
%\footnote{eliminated discussion of data set here; basics should now be given only in table 3}
%For the 987 manually aligned sentences, we compare our alignment with both gold, manual word alignments and GIZA++ alignments in Table 4. Results of the alignment are given out of 3276 predicates in the English sentences and 3917 predicates in the German sentences.


\begin{table}[t]
	\centering
	\begin{tabular}{lllr}
		\hline
		\cline{1-4}
		\small Classifier  & \small P  & \small R & \small F1\\
		\hline
		\small Majority Baseline     & \small {0}     & \small {0} & \small {0}\\
		\small SVM-ablated     & \small \bf {0.6805}     & \small \bf{0.4444} & \small \bf{0.5128}\\
		\small SVM-all     & \small 0.1555 & \small 0.2238 & \small 0.18333 \\
		\small Decision Tree-ablated   & \small 0.6682    & \small 0.4155 & \small 0.4934 \\
		\small Decision Tree-all  & \small  0.4134   & \small 0.2222 & \small 0.2748 \\
		\small Gradient Boosting-ablated & \small 0.6688     & \small 0.3777 & \small 0.4631\\
		\small Gradient Boosting-all & \small  0.6466  & \small 0.2222 & \small 0.3268 \\
		\hline
	\end{tabular}
	\caption{Precision, Recall and F$_1$ for the positive class ({\em implicit role}), with stratified 5-fold CV.}\label{results}
\end{table}

\subsection {Classification of Implicit Arguments}
The data set constructed in Section 4  resulted in 51 manually validated implicit roles and 649 negative instances that were input for classification. 

We measure precision, recall, and F$_{1}$ scores, and for the SVM and Gradient Boosting classifiers we experimented with parameters to optimize precision.  The SVM classifier with a linear kernel produced the highest scores, but results were closely followed by Decision Tree and Gradient Boosting classifiers. For the SVM classifier, we experimented with different regularization \{0.5, 1, 10, 20\} and class weight increments \{None, 1:2, 1:10\} and found the highest precision scores were achieved with C=0.5 and class weight 1:2. In Gradient Boosting, we experimented with max depth \{1, 2, 3\} and found the highest precision scores were obtained with a max depth of 2. 
 Since the data set is heavily biased towards the negative class,
 %, with positive instances at less than 10{\%} of the data, 
 we divided training and test sets with a stratified 5-fold cross-validation (CV). We later experimented with upsampling for the positive class but found no significant improvement.
 %The experiments were run on the input candidates that were
 %obtained with an alignment scoring threshold  $\Theta$ set at 0.2. --already say this in the paragraph above
 
{\bf  \flushleft Feature Ablation}
To determine the optimal feature set, we performed  ablation tests by incrementally removing a feature and performing training/testing over the reduced feature set. Ablation was performed individually for each classifier. After these tests, we eliminated features that caused a drop in performance and used only the best performing features in the final classification. The final feature set is shown in Table 5.

The SVM model obtains the best results of 0.68 precision and F$_1$-score of 0.51 with the ablated feature set, closely followed by the other classifier models and outperforming the majority baseline, which always predicts the negative class (see Table \ref{results} for both ablated and full feature results). 


{\bf  \flushleft Feature Analysis}
The final feature set used in the classification experiment included both cross-lingual features of the predicate and arguments on source/target sentences, as well as monolingual predicate and argument features. The ablation results support our initial hypothesis that the surrounding predicate/argument structures and alignment scores are relevant to the detection of an omitted role.

\begin{table}[t!]
\centering
\begin{tabular}{p{1cm}p{6cm}llr}
\toprule
 \small Type  &  \small Feature\\
 \midrule
\small \textit  a^{sl} &  lemma, POS, path to predicate\\
\small  \textit a^{sl}\text+1 & POS, path to predicate\\
\small \textit  a^{sl}\text{--}1  & alignment type, number of dependents\\
\small \textit p^{tl}   & POS\\
\small \textit  p^{tl}\text{--}1   & sum of  \textit{ArgAL_p} scores \\
\small \textit  p^{tl}\text+1   & POS, number of arguments, number of unaligned arguments, sum of   \textit{ArgAL_p} scores, alignment type\\
\bottomrule
\end{tabular}
\caption{Final feature set used in classification. Notation is defined in Section 3.1, where $\small \pm$ {\small 1}  are the arguments/predicates preceding {\small (\text{--}1)} and following {\small (\text+1)} the candidate.}\label{tab:accents}
\end{table}

\subsection{Analysis of Results}

{\bf  \flushleft Translation Shifts that Trigger Implicit Roles}
%Our analysis of the positive instances of implicit roles yielded a number of syntactic environments that trigger omission of semantic roles in translation. 
%I changed this since the analysis doesn't yield a syntactic environment, but rather we found the syntactic environments through analysis
Through observation of the positive instances, we determined a number of syntactic environments that trigger omission of semantic roles from English to German.
Shift in voice, finite to infinite verb forms, and coordination could all motivate the deletion of a role across translated sentences. While these syntactically licensed implicit roles composed 57{\%} of our positive instances, a large number (43{\%}) were not found to have an explanation on syntactic grounds alone. In these cases, the arguments seem to have been omitted by pragmatic or semantic factors. The distribution of these shift types over our dataset is given in Table \ref{shifts}.

\exewidth{(0)}
 {\bf \flushleft \textit{Voice}} A change  from active (source) to passive (target). Subjects are dropped in translation:
\begin{exe}
\ex  The more [we] \underline{refuse} to democratize the institutions ....
 \vspace*{-2mm}
\gll Je mehr die Demokratisierung der Institutionen \underline{verweigert} wird  ...\\
The more the democratization {of the} institution refused are\\
\end{exe}

{\bf \flushleft \textit{Coordination}} An argument might be the repeated subject of two conjoined clauses, but expressed as a shared argument in the parallel sentence:

\begin{exe}
\ex  I was faced with this system \textit{and} [I] do not \underline{know} any parliament
 \vspace*{-2mm}
\gll Ich fand dieses System vor \textit{und} \underline{kenne} kein Parlament\\
I faced this system before and  know no parliament\\
\end{exe}

 {\bf \flushleft \textit{Extraposition}} Complex clausal embeddings can cause roles to be extraposed from their predicates in the target language text:

\begin{exe}
	\ex  ...but would also want to \underline{encourage} both parties [to observe the spirit of this new agreement].
	\vspace*{-2mm}
	\gll ...er kann die beiden Parteien nur \underline{veranlassen} wollen, [den Geist dieses neuen Abkommens zu achten].\\
	...it can that both parties only encourage want, the spirit {of-this} new agreement to observe\\
\end{exe}

Coordination and extraposition are borderline cases with regard to the non-locality of roles.
PropBank does annotate coordinated arguments, and in these cases the syntactic parse tree can be leveraged for recovery of the non-local role.  However, we still consider these implicit arguments since they are expressed outside of the local scope of the predicates.
%Similar to the coordination examples, the non-local role can be recovered through traversal of the parse tree in extraposition.

 {\bf \flushleft \textit{Nonfinite}} Similar to change in voice, the subject of a finite verb can be dropped when the translated verb is nonfinite:

\begin{exe}
\ex  I would ask that [they] \underline{reconsider} these decisions
 \vspace*{-2mm}
\gll Ich bitte, diese Entscheidung \underline{zu {\"u}berdenken} \\
I ask, these decisions {to reconsider}\\
\end{exe}

 {\bf \flushleft \textit{Semantic/Pragmatic}} A role can be dropped in translation without a structural shift that licenses the omission. In these instances, the role could have been incorporated into the aligned sentence without a change to the syntactic environment.
\begin{exe}
\ex ... I am \underline{asking} you to do this directly, [in this House].
\gll ...\underline{wende} ich mich hiermit direkt an Sie .\\
...turn I myself hereby directly to you \\
\end{exe}

Since the directionality of our implicit role search focused on English to German, we do not account for syntactic shifts that could cause omissions in the opposite direction, i.e. German to English. There are imperative constructions in German that overtly encode the addressee of the command (``go outside'' in English can be translated as ``go \textit{you} outside'' in German) which can trigger implicit roles in translation from German to English.

\begin{table}[h]
\centering
\begin{tabular}{lllr}
\hline
\cline{1-3}
\small
Shift Type  & \small Count &  {\%} \\
\hline
\small Voice     & \small 7 & \small 14{\%}      \\
\small Coordination   & \small 8 &  \small 16{\%}     \\
\small Extraposition & \small 8 &  \small 16{\%}     \\
\small Nonfinite    & \small 6 & \small 11{\%}       \\
\small Semantic/Pragmatic  & \small 22 &  \small 43{\%}       \\
\hline
\end{tabular}
\caption{Shift types that trigger implicit roles.}\label{tab:accents}
\label{shifts}
\end{table}

{\bf  \flushleft Semantic Role Types of Omitted Arguments}
We adopt the VerbNet roleset \cite{kipper2000class} to manually label semantic role across all our implicit argument instances. A full analysis of the role types, shown in Table \ref{roles}, found that a majority of implicit roles are \textit{Agent} and \textit{Theme}. This reflects the general distributions for role frequency \cite{merlo2009abstraction}, but could also be due to the syntactic shifts that produce a higher omission of the subject, such as passivization and coordination, which are commonly filled by the \textit{Agent} and \textit{Theme} roles.

\begin{table}[h]
	\centering
	\begin{tabular}{llllr}
		\hline
		\cline{1-4}
		\small Core Role  & \small Count  & \small Non-Core Role & \small Count\\
		\hline
		\small Agent     & \small 15     & \small Time & \small 6 \\
		\small Theme   & \small 14     & \small Topic & \small 5 \\
		\small Recipient & \small 3      & \small Location & \small 3 \\
		\small Experiencer  & \small 2    & \small Manner & \small 1\\
		\small Cause    & \small 2    & & \\
		\hline
	\end{tabular}
	\caption{Thematic roles, both core and non-core, of the implicit cases.}\label{tab:accents}
	\label{roles}
\end{table}

{\bf  \flushleft Antecedents to the Implicit Role}
The analyses above described the shift types that trigger argument omission, but only two of these types, coordination and extraposition, would guarantee the missing argument to be recoverable from the non-local context. Cases where the annotators were able to recover the antecedent roles, either from the previous clause or sentences, were less than the majority (21 out of the 51 cases), while many instances were not instantiated in the non-local context. Table \ref{antecedent} gives the proportion of recovered antecedents according to shift types. The fact that extraposition and coordination cases yield higher number of resolvable roles can be exploited in future work for antecedent linking.

\begin{table}[h]
\centering
\begin{tabular}{lllr}
\hline
\cline{1-3}
\small
Shift Type  & \small Resolvable &  \small Not resolvable  \\
\hline
\small Voice     & \small 1 & \small 6    \\
\small Coordination   & \small 8 &  \small 0     \\
\small Extraposition & \small 8 &  \small 0    \\
\small Nonfinite    & \small 1 & \small  5     \\
\small Semantic/Pragmatic  & \small  3 &  \small 19      \\
\hline
\end{tabular}
\caption{Availability of the antecedent in the surrounding context.}
\label{antecedent}
\end{table}


%%%% begin new conclusion
\section{Conclusion and Future Work}
In this work, we investigated the hypothesis that implicit semantic roles can be identified in translation. Our method is knowledge-lean and achieves respectable performance despite a small training set. While the present work has focused on missing arguments of verbal predicates, implicit role detection in this multilingual framework can be easily extended to nominal predicates.
Combining both predicate types is expected to improve the overall results, as some of the noise we are currently observing pertains to implicit roles occurring with nouns.
%\footnote{{\color{red}I included this, and hope you can give a raw estimate about whether we find implicit arguments of nominals till Thursdady. You can extract some 20-50 cases and check them manually, that should be somewhat indicative as an estimate.}}
% I reinserted this: we should say something about the problem of automatic alignments and how to address it. I do not disclose that we could use multilingual embeddings but refer to triangulation - a well-known technique in working with parallel corpora and translation. I can explain it to you: if for word w we have alignment of G-F and F-E, but not G-E, we can trust G-F and F-E and include G-E.
Additional noise is produced by the automatic word alignments, which can be addressed by employing triangulation techniques using multiple language pairs. Further, with our current classifier we can predict role omissions across parallel sentences with better accuracy than reliance on noisy word alignments alone, and with these predictions we can generate better candidates for annotation and reduce the time and cost of future annotation effort.

%I commented out this section since it doesn't flow well with the previous and I think the last paragraph is sufficient
%We found that implicit roles accounted for approximately\ 10{\%} of the unaligned arguments in parallel sentences, and these implicit arguments can be caused by multiple types of syntactic divergences across language pairs. 
%Many of the semantic/pragmatic cases of implicit roles might be divided into more specific category types, such as differences in valency in verbs across languages or factors in discourse that motivate a dropped semantic role.
%We hypothesize that these shifts should trigger non-local semantic roles in translation with some systematicity. 
%I would say that we have already shown that much.
%By extending the approach to larger and more varied corpora from different genres, we expect to identify more constructional variants and semantic/pragmatic cases of implicit roles. Investigations in these directions are expected to shed more light on the full scope of omissions in argument structures in multilingual corpora.
%After maximizing classifier precision, we can look to scale up our search for implicit roles over larger multilingual datasets with various genres and domains. 
%I have taken out maximization of precision. We have already maximized precision.

A next step from the current work would be to automatically recover the antecedent of the implicit role in the target language when it is available. 
By doing so, we can construct new training data for monolingual implicit role labeling, improve transference of semantic roles across parallel corpora, and generate novel training data for implicit role labeling for new languages.
%%%%% end new conclusion

%%%%% begin old conclusion
\if false
\section{Conclusion and Future Work}
In this work, we investigated the hypothesis that implicit semantic roles can be identified in translation. Our method is knowledge-lean and achieves respectable performance despite a small training set.
While this work has focused on the missing arguments of verbal predicates, implicit role detection in this multilingual framework can be easily extended to nominal predicates. Additionally, many of the semantic/pragmatic cases of implicit roles might be divided into more specific category types, such as differences in valency in verbs across languages or factors in discourse that motivate a dropped semantic role. A future direction to the current work would be to automatically link the implicit arguments in the source language with its non-local argument in the target language text when the antecedent is available. Investigations in these directions are expected to shed more light on the full scope of omissions in argument structures in multilingual corpora.

We found that implicit roles accounted for approximately\ 10{\%} of the unaligned arguments in parallel sentences, and these implicit arguments can be caused by multiple types of syntactic divergences across language pairs. We hypothesize that these shifts should trigger non-local semantic roles in translation with some systematicity. After maximizing classifier precision, we can look to scale up our search for implicit roles over larger multilingual datasets with various genres and domains. By doing so, we can rapidly construct new training data for monolingual implicit role labeling, improve transference of semantic roles across parallel corpora, and generate novel training data for implicit role labeling for new languages.

%Anette conclusion:
%In this work we investigated the hypothesis that implicit semantic roles can be identified in translation. Our method is knowledge-lean and achieves respectable performance despite a small training set. 
%SAME AS CURRENT
%We plan to apply the existing classifier in an active learning scenario to improve its performance.
%INES SEEMED TO THINK THIS MIGHT BE PROBLEMATIC FOR OUR CURRENT WORK - NOT SURE IF WE SHOULD ADD THIS?
%Further gains can be achieved by interfacing the unaligned argument detection and classification steps in a joint classification task.
%THIS IS A STRANGE USE OF THE WORD INTERFACE, AND ALSO I DON'T KNOW HOW THESE GAINS WOULD BE ACHIEVED BY COMBINING THE TWO - NEEDS FURTHER EXPLANATION IF IT'S TO BE INCLUDED
%
%Our current work focuses on verbal predicates. In the future we will include nominals. Combining both predicate types is expected to improve overall results, as much of the 'noise' we are currently observing pertains to implicit roles occuring with nouns.
%INCLUDED IN THE CURRENT CONCLUSION
%By extending the approach to larger and varied corpora, we expect to identify more constructional variants and semantic/pragmatic cases of implicit roles, such as differences in valence requirements across languages, and discourse factors that motivate role omission.
%INCLUDED IN THE CURRENT CONCLUSION
%%These investigations are expected to shed more light on the full scope of omissions in argument structures in multilingual corpora.
%INCORPORATED IN THE CURRENT CONCLUSION
%
%Our present work is still restricted to the detection of implicit roles via translation correspondence. To recover full-fledged training data for non-local SRL, we will transfer the method of \newcite{Roth:14} to the multilingual setting.
%THIS NEEDS MORE EXPLANATION - WHAT SPECIFIC METHOD IS BEING REFERRED TO HERE? ALSO WE'RE NOT SURE IF THIS IS WHAT WE ACTUALLY WANT TO DO.
%
%In our study focusing on verbs we found that implicit roles occur in approx.\ 10{\%} of detected unaligned arguments in parallel sentences. This ratio dropped with automatically aligned corpora.
%INCLUDED IN THE CURRENT CONCLUSION
%Alignment errors can be alleviated using multiple language pairs.
%THIS NEEDS MORE EXPLANATION ALSO - HOW WOULD MULTIPLE LANGUAGE PAIRS ALLEVIATE ERRORS IN THE ALIGNMENT? ALSO I THINK THIS MIGHT BE STRETCHING OUR CLAIMS FOR THIS APPROACH FARTHER THAN WE WANT TO GO
%A major advantage over existing models that acquire training data for non-local SRL is that our model can be applied to multiple languages, using available large-scale multilingual corpora of various genres and domains.
% INCORPORATED IN THE CURRENT CONCLUSION
\fi
\section{Acknowledgments}
This research has been conducted within the Leibniz Science Campus ``Empirical Linguistics and Computational Modeling",
funded by the Leibniz Association under grant no.\ SAS-2015-IDS-LWC and by the Ministry of Science, Research, and Art (MWK) of the state of Baden-W\"urttemberg. We thank  our annotators Leo Born, Max M\"uller-Eberstein and Julius Steen for their contribution.

\bibliography{acl2016}
\bibliographystyle{acl2016}

\appendix

\end{document}
